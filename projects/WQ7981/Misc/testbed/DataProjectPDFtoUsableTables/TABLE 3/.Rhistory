for (table.row in  seq(2, numRows, 1)) {           # assign row  (was 2,37, 4)
for (table.col in 2:8){          # assign collum
if (toString(origData[table.row,table.col]) == "NA") {   # skip lines with no data
next
}
stationName <- toString(origData[table.row,1])
surveyTimestamp <- toString(origData[1,table.col])
surveyData <- toString(origData[table.row,table.col])
l <- c(stationName, surveyTimestamp, surveyData )  # create a vector of data
#print(l)
#write vector to data frame results.frame if it exists, create one if it does not
# this will add it as a column, which will be tansposed to a row later on
if (exists("results.frame") ) {
results.frame[,results.col] <- c(l)
} else {
results.frame <- data.frame(l)
}
results.col <- results.col + 1  # Move to next col
}    #end for col
} # end for row
return(results.frame)
} # end function
join_frames <- function (df1, df2) {  # Function to join two data frames
#combine the data from the 2 files
r.df <- union(df1, df2)
names(r.df) <- union(names(df1), names(df2))
r.df <- as.data.frame(r.df)
return(r.df)
}
##MAIN SCRIPT##
#t.info <- list( files = 2, dir = 'Table 3', file.one = 16, label = "Chem Oxy DD") # List of info for table to be processed
ProcessOneTable <- function ( t.table.number ,
t.number.files,
t.label <- "Chem Oxy DD",
t.first.file ){
new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/Table",t.num)
setwd(new.dir)
## extract data from all the files in a table directory and combine them into one data frame
for (files.num in 0:(t.number.files - 1)) {
origFile <- paste(t.first.file + files.num, ".csv", sep = "")  # establish file name to process each file in dir
print(paste("Processing",origFile))
# call function to extact data from file
r.frame1 <- ExtractOneFile(origFile,4, 55)   #variables: file, rows to skip, rows to process
## determine if combined frame exists - should not for first file - create if not, join with existing frame if so
if (exists("r.frame") ) {
r.frame <- join_frames( r.frame, r.frame1)
} else {
r.frame <- r.frame1
}
}
df.save <- as.data.frame(t(r.frame))  # transpose frame from columns of data to rows of data
#add column names
colnames(df.save) <- c("LocationID","Datetime",t.label)
#df.save <- subset(df.save, select = -c(drop))  # remove the filler column (was a row) we needed to add above
file.name <- paste("Table",t.table.number, "mod.csv", sep = "")  # use the direcory name/table name in the file name
# write the results out to a file, from processing one or more files to a single csv file with linear usable data
write.table(df.save, file = file.name,
append = FALSE, quote = TRUE, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE,
qmethod = c("escape", "double"), fileEncoding = "")
}
table.number <- 3
number.files <- 2
label <- "Chem Oxy DD"
first.file <- 16
ProcessOneTable(table.number,
number.files ,
label ,
first.file)
# transpose tables 3 - 33, of the Mystic River data project
#Peter Olsen
# April, 2015
#
require(stringr)
require(lubridate)
#setwd("/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/TABLE 3")
rm(list=ls())   # remove all variables in Enviornment
#FUCNTION#
convert.time <- function(tbl.date, tbl.time){    #function to take date and time and return a timestamp
# Format time so it can be used
if (tbl.time == "NA"){
tbl.time <- "0000"
}
st.min <- str_sub(tbl.time,-2,-1)  # gets min  - 1st and second digit from right
st.hour <- str_sub(tbl.time, 1, -3)  #gets hours - 1st digit from Left to 3rd digit from right
# can handle 1 or 2 digit hour values
new.time <- paste(st.hour, st.min, sep=":")  # combine to create hour:min  "11:50"
#new.time                                      # print result, for testing
#Format Date so it can be used and is in the 1900's
new.date <- as.Date(tbl.date, format = "%m/%d/%y") # rearanges date to ""1979-12-12"
#with as.Date - /79 is 1979 not 2079
#new.date                                 # print result, for testing
#paste date and time together
new.dt <- paste(new.date, new.time, sep=" ")  # gives format "1979-12-12 11:50"
#new.dt                                         # print result, for testing
final.date <- toString(ymd_hm(new.dt, tz = "EST"))       # gives "1979-12-12 11:50:00 EST" ; desired format
#final.date
return(final.date)
} # end convert time function
#Fuction to Extact data from one file from a Table
ExtractOneFile <- function (origFile,numRowSkip,numRows = 43) {
origData <- read.table (file = origFile, header = FALSE, sep = ",", skip=numRowSkip, na.strings = c(""))
#print(origData)
results.col <- as.integer(1)
print(results.col)
for (table.row in  seq(2, numRows, 1)) {           # assign row  (was 2,37, 4)
for (table.col in 2:8){          # assign collum
if (toString(origData[table.row,table.col]) == "NA") {   # skip lines with no data
next
}
stationName <- toString(origData[table.row,1])
surveyTimestamp <- toString(origData[1,table.col])
surveyData <- toString(origData[table.row,table.col])
l <- c(stationName, surveyTimestamp, surveyData )  # create a vector of data
#print(l)
#write vector to data frame results.frame if it exists, create one if it does not
# this will add it as a column, which will be tansposed to a row later on
if (exists("results.frame") ) {
results.frame[,results.col] <- c(l)
} else {
results.frame <- data.frame(l)
}
results.col <- results.col + 1  # Move to next col
}    #end for col
} # end for row
return(results.frame)
} # end function
join_frames <- function (df1, df2) {  # Function to join two data frames
#combine the data from the 2 files
r.df <- union(df1, df2)
names(r.df) <- union(names(df1), names(df2))
r.df <- as.data.frame(r.df)
return(r.df)
}
##MAIN SCRIPT##
#t.info <- list( files = 2, dir = 'Table 3', file.one = 16, label = "Chem Oxy DD") # List of info for table to be processed
ProcessOneTable <- function ( t.table.number ,
t.number.files,
t.label,
t.first.file ){
new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/Table",t.num)
setwd(new.dir)
## extract data from all the files in a table directory and combine them into one data frame
for (files.num in 0:(t.number.files - 1)) {
origFile <- paste(t.first.file + files.num, ".csv", sep = "")  # establish file name to process each file in dir
print(paste("Processing",origFile))
# call function to extact data from file
r.frame1 <- ExtractOneFile(origFile,4, 55)   #variables: file, rows to skip, rows to process
## determine if combined frame exists - should not for first file - create if not, join with existing frame if so
if (exists("r.frame") ) {
r.frame <- join_frames( r.frame, r.frame1)
} else {
r.frame <- r.frame1
}
}
df.save <- as.data.frame(t(r.frame))  # transpose frame from columns of data to rows of data
#add column names
colnames(df.save) <- c("LocationID","Datetime",t.label)
#df.save <- subset(df.save, select = -c(drop))  # remove the filler column (was a row) we needed to add above
file.name <- paste("Table",t.table.number, "mod.csv", sep = "")  # use the direcory name/table name in the file name
# write the results out to a file, from processing one or more files to a single csv file with linear usable data
write.table(df.save, file = file.name,
append = FALSE, quote = TRUE, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE,
qmethod = c("escape", "double"), fileEncoding = "")
}
table.number <- 3
number.files <- 2
label <- "Chem Oxy DD"
first.file <- 16
ProcessOneTable(table.number,
number.files ,
label ,
first.file)
# transpose tables 3 - 33, of the Mystic River data project
#Peter Olsen
# April, 2015
#
require(stringr)
require(lubridate)
#setwd("/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/TABLE 3")
rm(list=ls())   # remove all variables in Enviornment
#FUCNTION#
convert.time <- function(tbl.date, tbl.time){    #function to take date and time and return a timestamp
# Format time so it can be used
if (tbl.time == "NA"){
tbl.time <- "0000"
}
st.min <- str_sub(tbl.time,-2,-1)  # gets min  - 1st and second digit from right
st.hour <- str_sub(tbl.time, 1, -3)  #gets hours - 1st digit from Left to 3rd digit from right
# can handle 1 or 2 digit hour values
new.time <- paste(st.hour, st.min, sep=":")  # combine to create hour:min  "11:50"
#new.time                                      # print result, for testing
#Format Date so it can be used and is in the 1900's
new.date <- as.Date(tbl.date, format = "%m/%d/%y") # rearanges date to ""1979-12-12"
#with as.Date - /79 is 1979 not 2079
#new.date                                 # print result, for testing
#paste date and time together
new.dt <- paste(new.date, new.time, sep=" ")  # gives format "1979-12-12 11:50"
#new.dt                                         # print result, for testing
final.date <- toString(ymd_hm(new.dt, tz = "EST"))       # gives "1979-12-12 11:50:00 EST" ; desired format
#final.date
return(final.date)
} # end convert time function
#Fuction to Extact data from one file from a Table
ExtractOneFile <- function (origFile,numRowSkip,numRows = 43) {
origData <- read.table (file = origFile, header = FALSE, sep = ",", skip=numRowSkip, na.strings = c(""))
#print(origData)
results.col <- as.integer(1)
print(results.col)
for (table.row in  seq(2, numRows, 1)) {           # assign row  (was 2,37, 4)
for (table.col in 2:8){          # assign collum
if (toString(origData[table.row,table.col]) == "NA") {   # skip lines with no data
next
}
stationName <- toString(origData[table.row,1])
surveyTimestamp <- toString(origData[1,table.col])
surveyData <- toString(origData[table.row,table.col])
l <- c(stationName, surveyTimestamp, surveyData )  # create a vector of data
#print(l)
#write vector to data frame results.frame if it exists, create one if it does not
# this will add it as a column, which will be tansposed to a row later on
if (exists("results.frame") ) {
results.frame[,results.col] <- c(l)
} else {
results.frame <- data.frame(l)
}
results.col <- results.col + 1  # Move to next col
}    #end for col
} # end for row
return(results.frame)
} # end function
join_frames <- function (df1, df2) {  # Function to join two data frames
#combine the data from the 2 files
r.df <- union(df1, df2)
names(r.df) <- union(names(df1), names(df2))
r.df <- as.data.frame(r.df)
return(r.df)
}
##MAIN SCRIPT##
#t.info <- list( files = 2, dir = 'Table 3', file.one = 16, label = "Chem Oxy DD") # List of info for table to be processed
ProcessOneTable <- function ( t.table.number ,
t.number.files,
t.label,
t.first.file ){
new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/Table",table.number)
setwd(new.dir)
## extract data from all the files in a table directory and combine them into one data frame
for (files.num in 0:(t.number.files - 1)) {
origFile <- paste(t.first.file + files.num, ".csv", sep = "")  # establish file name to process each file in dir
print(paste("Processing",origFile))
# call function to extact data from file
r.frame1 <- ExtractOneFile(origFile,4, 55)   #variables: file, rows to skip, rows to process
## determine if combined frame exists - should not for first file - create if not, join with existing frame if so
if (exists("r.frame") ) {
r.frame <- join_frames( r.frame, r.frame1)
} else {
r.frame <- r.frame1
}
}
df.save <- as.data.frame(t(r.frame))  # transpose frame from columns of data to rows of data
#add column names
colnames(df.save) <- c("LocationID","Datetime",t.label)
#df.save <- subset(df.save, select = -c(drop))  # remove the filler column (was a row) we needed to add above
file.name <- paste("Table",t.table.number, "mod.csv", sep = "")  # use the direcory name/table name in the file name
# write the results out to a file, from processing one or more files to a single csv file with linear usable data
write.table(df.save, file = file.name,
append = FALSE, quote = TRUE, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = FALSE, col.names = TRUE,
qmethod = c("escape", "double"), fileEncoding = "")
}
table.number <- 3
number.files <- 2
label <- "Chem Oxy DD"
first.file <- 16
ProcessOneTable(table.number,
number.files ,
label ,
first.file)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=numRowSkip, na.strings = c(""))
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
View(df.names)
df.names[1]
df.names[reportRow,1]
NameChange <- function(st.name){
#new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/)
#setwd(new.dir)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
for (reportRow in 1:nrow(Report.frame)){
if (df.names[reportRow,1] == st.name) {
return( df.names[reportRow,2])
}
}
}
x <- NameChange(AJ01)
print(x)
NameChange <- function(st.name){
#new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/)
#setwd(new.dir)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
for (reportRow in 1:nrow(df.names)){
if (df.names[reportRow,1] == st.name) {
return( df.names[reportRow,2])
}
}
}
x <- NameChange(AJ01)
print(x)
StationNameChange <- function(st.name){
#new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/)
#setwd(new.dir)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
for (reportRow in 1:nrow(df.names)){
if (df.names[reportRow,1] == st.name) {
return( df.names[reportRow,2])
}
}
}
x <- StaionNameChange("AJ01")
print(x)
StationNameChange <- function(st.name){
#new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/)
#setwd(new.dir)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
for (reportRow in 1:nrow(df.names)){
if (df.names[reportRow,1] == st.name) {
return( df.names[reportRow,2])
}
}
}
x <- StationNameChange("AJ01")
print(x)
StationNameChange <- function(st.name){
#new.dir <- paste("/Users/Peter/Documents/MysticProject/testbed/)
#setwd(new.dir)
Names.File <- "/Users/Peter/Documents/MysticProject/testbed/DataProjectPDFtoUsableTables/scripts/LocationChangeData.csv"  # establish file name to process each file in dir
#Names.File <- ()
df.names <- read.table (file = Names.File, header = FALSE, sep = ",", skip=1, na.strings = c(""))
for (reportRow in 1:nrow(df.names)){
if (df.names[reportRow,1] == st.name) {
return( df.names[reportRow,2])
}
}
}
x <- StationNameChange("AJ02")
print(x)
dropbox.data <- repmiss(x)
install.packages("repmis")
test.name <- "https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv"
FinRegulatorData <- repmis::source_data(test.name,
sep = ",",
header = TRUE)
FinRegulatorData
test.name <- "https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv"
FinDataFull <- repmis::source_DropboxData("7.csv",
"zg2axbhh0j3um37",
sep = ",",
header = TRUE)
test.name <- "https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv"
FinDataFull <- repmis::source_DropboxData("7.csv",
"zg2axbhh0j3um37",
sep = ",",
header = FALSE)
x <- read.table(test.name)
test.name <- "https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv"
FinDataFull <- repmis::source_DropboxData("7.csv",
"zg2axbhh0j3um37",
sep = ",",
header = FALSE)
https://www.dropbox.com/s/zg2axbhh0j3um37/7.csv?dl=0
x <- origData <- read.table (file = test.name, header = FALSE, sep = ",", skip=numRowSkip, na.strings = c(""))
test.name <- url("https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv")
FinDataFull <- repmis::source_DropboxData("7.csv",
"zg2axbhh0j3um37",
sep = ",",
header = FALSE)
https://www.dropbox.com/s/zg2axbhh0j3um37/7.csv?dl=0
x <- origData <- read.table (file = test.name, header = FALSE, sep = ",", skip=numRowSkip, na.strings = c(""))
library(RODBC)
library(plyr)
library(dplyr)
library(lubridate)
library(tidyr)
library(ggplot2)
library(ggmap)
library(wq)
setwd("C:/Users/Volunteer Intern/Dropbox/MysticDB")
source("./Rcode/Sandbox/Jeff/load_wq.R")
wq <- load_wq(exclude.qaqc.samples=FALSE)
source('./Rcode/Sandbox/Jeff/load_precip.R')
precip <- load_precip()
wq2 <- append_weather(wq,precip)
## 1.Preparing data for the "Sample data" sheet
#Select regular baseline (no field duplicates) data with DEP format required fields
BASEDATA <- wq2 %>%
select(WaterBodyID, LocationID, LocationDescription, Latitude, Longitude,
VisitID, Datetime, CharacteristicName, Units, ResultValue,
ProjectID, SampleTypeID) %>%
filter(ProjectID == "BASE", SampleTypeID == "S")
BASEDATA <- BASEDATA %>% mutate(Watershed = "Boston Harbor: Mystic")
BASEDATA <- BASEDATA %>% mutate(FlowCondition = "Flowing")
#Extracting Date only from Datetime
BASEDATA$SampleDate <- as.Date(BASEDATA$Datetime)
#Extracting time only from Datetime
BASEDATA$SampleTime <- format(as.POSIXct(BASEDATA$Datetime, format="%Y-%m-%d %H:%M:%S"), format="%H:%M")
#Changing columns order to fit DEP template
BASEDATA <- BASEDATA[c("Watershed", "WaterBodyID", "LocationID", "LocationDescription",
"Latitude", "Longitude", "VisitID", "SampleDate", "SampleTime",
"FlowCondition", "CharacteristicName", "Units", "ResultValue")]
#Changing columns names to fit DEP template
colnames(BASEDATA) <- c("Watershed", "WaterBody", "StationID", "StationDescription",
"Latitude_WGS84", "Longitude_WGS84", "SampleID", "SampleDate",
"SampleTime", "FlowCondition", "Analyte","Units", "Result")
#Export BASEDATA as a text file
write.table(BASEDATA, "C:/Users/Volunteer Intern/Desktop/Basedata.txt",
sep="\t", row.names = FALSE)
## 2.Preparing data for the "field qc data" sheet - Field duplicates (and not Field blanks)
#Select FD data and expand results as required by DEP for this sheet
FD <- wq2 %>%
select(VisitID, Datetime, CharacteristicID, ResultValue, LocationID,
ProjectID, SampleTypeID) %>%
filter(ProjectID == "BASE", SampleTypeID == "FD") %>%
spread(CharacteristicID, ResultValue)
#Add a date only column
FD$SampleDate <- as.Date(FD$Datetime)
#Add a time only column
FD$SampleTime <- format(as.POSIXct(FD$Datetime, format="%Y-%m-%d %H:%M:%S"), format="%H:%M")
#Concatenate Date and Location which makes a unique couple for each FD
#Extract this new column as a Value
FD <- FD %>% mutate(Filt = paste(FD$LocationID, FD$SampleDate,sep="/"))
Filter <- FD[,"Filt"]
#Drop useless columns
drops <- c("Datetime", "LocationID", "ProjectID")
FD <- FD[,!(names(FD) %in% drops)]
#Select regular data and expand results as required by DEP for this sheet
#Add a date only column
#Add a time only column
S <- wq2 %>%
select(VisitID, Datetime, CharacteristicID, ResultValue, LocationID,
ProjectID, SampleTypeID) %>%
filter(ProjectID == "BASE", SampleTypeID == "S") %>%
spread(CharacteristicID, ResultValue)
S$SampleDate <- as.Date(S$Datetime)
S$SampleTime <- format(as.POSIXct(S$Datetime, format="%Y-%m-%d %H:%M:%S"), format="%H:%M")
#Concatenate Date and Location as for FD data to be able to match each FD
#with its matching regular sample
S <- S %>% mutate(Filt = paste(S$LocationID, S$SampleDate,sep="/"))
#Drop useless columns
drops <- c("Datetime", "LocationID", "ProjectID")
S <- S[,!(names(S) %in% drops)]
#Extract regular samples with a matching FD
SmatchFD <- subset(S, Filt %in% Filter)
#Make sure events are in the same order in FD and SmatchFD
FD <- FD[ order(FD[,"Filt"]), ]
SmatchFD <- SmatchFD[ order(SmatchFD[,"Filt"]), ]
#Add corresponding FD VisitID to regular samples and regular sample VisitID to FD
FD_VisitID <- FD$VisitID
SmatchFD <- SmatchFD %>% mutate(QCMatch = FD_VisitID)
SmatchFD_VisitID <- SmatchFD$VisitID
FD <- FD %>% mutate(QCMatch = SmatchFD_VisitID)
#Calculate RPD in a dataframe similar to FD and SmatchFD
c1 <- c("VisitID", "SampleTypeID")
c2 <- c("DO", "DO_SAT", "ECOLI", "ENT", "FCOLI", "NH3", "NO2", "NO23", "NO3", "PH",
"SALINITY", "SPCOND", "TEMP_WATER", "TN", "TP", "TSS", "TURB")
c3 <- c("SampleDate", "SampleTime", "Filt", "QCMatch")
RPD <- data.frame(FD[,c1], (abs(FD[,c2]-SmatchFD[,c2])*2*100/(FD[,c2]+SmatchFD[,c2])), FD[,c3])
#Fill VisitID, SampleTypeID, and QCMatch with blanks to match DEP template
RPD$VisitID <- rep(c("RPD"),nrow(RPD))
RPD$SampleTypeID <- rep(c(""),nrow(RPD))
RPD$QCMatch <- rep(c(""),nrow(RPD))
#Merge dataframe of regular samples with matching FD, dataframe of FD, and dataframe of RPD
FDandMatchS <- rbind(SmatchFD, FD)
FD_Final <- rbind(FDandMatchS, RPD)
#Order rows to have S/FD/RPD in that order for each event
FD_Final <- FD_Final[ order(FD_Final[,"SampleDate"], FD_Final[,"Filt"]), ]
#Add Flow condition to meet DEP template requirements
FD_Final <- FD_Final %>% mutate(FlowCondition = "Flowing")
#Changing columns order to fit DEP template
FD_Final <- FD_Final[c("VisitID", "SampleTypeID", "QCMatch", "SampleDate",
"SampleTime", "FlowCondition", "DO", "DO_SAT", "ECOLI", "ENT", "FCOLI",
"NH3", "NO2", "NO23", "NO3", "PH", "SALINITY", "SPCOND", "TEMP_WATER",
"TN", "TP", "TSS", "TURB")]
#Changing columns names to fit DEP template
colnames(FD_Final) <- c("SampleID", "SampleType", "QCMatch", "SampleDate", "SampleTime",
"FlowCondition", "Dissolved Oxygen", "Dissolved Oxygen, % saturation",
"Escherichia coli", "Enterococcus", "Fecal Coliform", "Ammonia",
"Nitrite", "Nitrate + Nitrite", "Nitrate", "pH", "Salinity",
"Specific conductance", "Water Temperature", "Total Nitrogen",
"Total Phosphorus", "Total suspended solids", "Turbidity")
#Export FDandMatchS as a text file
write.table(FD_Final, "C:/Users/Volunteer Intern/Desktop/FDdata.txt", sep="\t", row.names = FALSE)
library(RODBC)
DB_PATH <-
url("https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv")
ch<- odbcConnectExcel2007(DB_PATH)
install.packages("RODBC")
library(RODBC)
DB_PATH <-
url("https://www.dropbox.com/home/WQ7981/ExcelShortNamesSortedByTableCSVFormat/Tables/TABLE%201/7.csv")
ch<- odbcConnectExcel2007(DB_PATH)
